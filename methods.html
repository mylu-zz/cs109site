<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Give It Five Stars! by mylu</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
            <link href="stylesheets/bootstrap.css" rel="stylesheet"/>
        <link href="stylesheets/bootstrap-responsive.css" rel="stylesheet"/>
        <link href="stylesheets/styles.css" rel="stylesheet"/>
        <script src="javascript/bootstrap.js"></script>
        <script src="javascript/main.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>

    <div class="wrapper">
      <header>
        <h1>Give It Five Stars!</h1>
        <p>An Exploration of Amazon Product Reviews</p>
        <p>
        Linda Du</br>
        Max Lu</br>
        Daniel Park</p>

        <p class="view"><a href="https://github.com/mylu/cs109site">View the Project on GitHub <small>mylu/cs109site</small></a></p>


        <ul>
          <li><a href="https://github.com/mylu/cs109site/zipball/master">Download <strong>ZIP File</strong></a></li>
          <li><a href="https://github.com/mylu/cs109site/tarball/master">Download <strong>TAR Ball</strong></a></li>
          <li><a href="https://github.com/mylu/cs109site">View On <strong>GitHub</strong></a></li>
        </ul>
        <a href="index.html">Home</a><br>
        <a href="overview.html">Overview</a><br>
        <a href="analysis.html">Analysis</a><br>
        <a href="methods.html">Methods</a><br>
        <a href="results.html">Results</a><br>
      </header>
      <section>
          <h3> Methods </h3>
          In order to examine the relationship between review text and scores, we build classifiers to predict score based on text features. We outline our three approaches below:
          </br><h5> Bag of Words </h5>
          <p>The "bag-of-words" or N-gram model looks to see whether the words or combination of words, and the frequency of these combinations can be used to predict the score of a product review.The text of the review is broken up first into "tokens" or "N-grams." A 1-gram (also called unigram or simply bag-of-words) is a collection of single words. A 2-gram/bigram is a collection of two word tokens. A 3-gram/trigram is a collection of 3 word tokens and so on. 
          </p><p>For example, the sentence "Daniel likes to play football." can be tokenized in several different ways using n-gram models:
          </p><p>Unigram: ['Daniel', 'likes', 'to', 'play', 'football']</br>
          Bigram: ['Daniel likes', 'likes to', 'to play', 'play football']</br>
          Trigram: ['Daniel likes to', 'likes to play', 'to play football']
          </p><p>Once the collection of n-grams is made, the number of occurances of each n-gram is tallied, and this information is passed to the classifier. The classifier will then classify based on the n-grams in the collection as well as their frequencies. n-grams that are very unique and occur often within a specific set of documents are more informative than n-grams that appear in all documents. So in classifying reviews, words like "I" or "bought" might be uninformative while words like "fantastic" might be more specific to highly rated reviews.  
          </p>
          </br><h5> Sentiment Analysis </h5>
          </br><h5> Latent Dirichlet Allocation </h5>
          <p>Latent Dirichlet Allocation (LDA) models product reviews using a mixture of hidden topics. The model assumes that when we generate a review, we choose a topic according to the review's topic distribution, and then from that topic, we choose a word according to another probability distribution. For example, consider Electronics reviews. The hidden topics are not well defined, but one may be associated with battery life, and another may be associated with durability. The battery life topic may generate words like "recharge", "cycle", or "long-lasting" with high probability, whereas the durability topic may generate words like "casing", "solid", and "rugged" with high probability. LDA tries to determine the relative proportions of each topic in our review; we want to say this review is 75% about battery life and 25% about durability. 
          </p><p>To do this, we keep track of each review's topic mixture and each topic's word distribution. We first assign words to topics (for example, we say that a particular occurrence of "recharge" was generated by the durability topic). Then, we continuously update our assignments using a method called Gibbs Sampling. For each word, based on the information we have, we recalculate the probability of a topic generating the word and then reassign that word to another topic according to those probabilities. This iterative update process will eventually converge and return a topic mixture for each review. For our purposes, we use LDA to discover 20 hidden topics.</p>
          
      </section>
      <footer>
        <p>This project is maintained by <a href="https://github.com/mylu">mylu</a></p>
        <p><small>Hosted on GitHub Pages &mdash; Theme by <a href="https://github.com/orderedlist">orderedlist</a></small></p>
      </footer>
    </div>
    <script src="javascripts/scale.fix.js"></script>
    
  </body>
</html>

